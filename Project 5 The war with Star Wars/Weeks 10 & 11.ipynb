{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 10 Tuesday Notes\n",
    "\n",
    "top row is the question\n",
    "\n",
    "second row has the options of the answers to the question\n",
    "\n",
    "I think pivoting is what one-hot-encoding does\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/fivethirtyeight/data/raw/master/star-wars-survey/StarWars.csv'\n",
    "\n",
    "sw_responses = pd.read_csv(url, encoding = \"ISO-8859-1\", header = None, skiprows = 2) \n",
    "sw_questions = pd.read_csv(url, encoding = \"ISO-8859-1\", header = None, nrows = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how can we preform a case_when() in python?\n",
    "- replace()?\n",
    "- dictionary method?\n",
    "\n",
    "Series v. Dataframe: \n",
    "- series is a one dementional frame (one column)\n",
    "- dataframe is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is the first row number and \":\" is the select all (think \"*\" in SQL)\n",
    "# dat_1.iloc[0, :].str.lower()\n",
    "# .str.replace(\" \", \"_\")\n",
    "# .ffill()\n",
    "\n",
    "\n",
    "bob = (sw_questions\n",
    "       .iloc[0,:]\n",
    "       .replace(\"Have you seen any of the 6 films in the Star Wars franchise?\", \"seen_any\")\n",
    "       .replace(\"Do you consider yourself to be a fan of the Star Wars film franchise?\", \"is_fan_star_wars\")\n",
    "       .replace(\"Which of the following Star Wars films have you seen? Please select all that apply.\", \"seen_\")\n",
    "       .str.lower()\n",
    "       .str.replace(\" \", \"_\")\n",
    "       .ffill()\n",
    ")\n",
    "bob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mary = (sw_questions\n",
    "        .iloc[1,:]\n",
    "        .replace(\"Response\", \"\")\n",
    "        .str.replace(\"Star Wars: Episode\", \"\")\n",
    "        .str.lower()\n",
    "        .str.replace(\" \", \"_\")  #partial match, not full match\n",
    "        .fillna(\"\") #replace function specifically for NA values\n",
    ")\n",
    "mary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column = bob + mary\n",
    "new_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three code chunks above are GQ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_responses.columns = new_column\n",
    "\n",
    "sw_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    dat_1\n",
    "    .value_counts(['gender', 'seen_any'], sort = False)\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat_1.gender.value_counts(normalize = True) # normalize does the math for you. Takes each and divided is by n()\n",
    "(dat_1\n",
    ".query(\"gender == 'Female' & seen_any == 'Yes'\")\n",
    ".is_fan_sw\n",
    ".value_counts(normalize = True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code chunks above are one of the numerical summaries proven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First graph in the article - \"Which 'Star Wars' Movies Have You Seen?\"\n",
    "\n",
    "# dat_1.seen_any.value_counts() # what-what?\n",
    "(\n",
    "dat_1\n",
    ".filter(regex='^seen__')\n",
    ".dropna(how=\"all\")\n",
    ".shape\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is making a graph in the article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On tuesday we'll do text data stuff.\n",
    "\n",
    "Watch the video she'll post on this.\n",
    "\n",
    "The take method's test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sw_responses.query(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 11 Tuesday Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot = (sw_data['which_character_shot_first?']\n",
    "    .dropna()\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "shot[\"percent\"] = round(shot['which_character_shot_first?']*100, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1 = (\n",
    "alt.Chart(shot)\n",
    "   .mark_bar()\n",
    "   .encode(\n",
    "       x = alt.X('which_character_shot_first?', \n",
    "                 axis = None), \n",
    "       y = alt.Y('index', sort = [\"Han\", \"Greedo\", \"I don't understand this question\"], \n",
    "                 axis = None)\n",
    "    )\n",
    ")\n",
    "part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part2 = (\n",
    "alt.Chart(shot)\n",
    "    .mark_text(\n",
    "        align = 'left', \n",
    "        baseline = 'middle', \n",
    "        dx = 3\n",
    "    )\n",
    "    .encode(\n",
    "        x = 'which_character_shot_first?', \n",
    "        y = alt.Y('index', \n",
    "                  sort = [\"Han\", \"Greedo\", \"I don't understand this question\"]), \n",
    "                  text = \"percent\"\n",
    "    )\n",
    ")\n",
    "part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(part1 + part2).properties(\n",
    "    title = {\n",
    "        \"text\": [\"Who Shot First\"], \n",
    "        \"subtitle\": [\"According to 828 Respondents\"]\n",
    "    }\n",
    ").configure(\n",
    "    background = \"#f0f0f0\"\n",
    ").configure_title(\n",
    "    anchor = \"start\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.factorize()\n",
    "pd.get_dummies(sw_data[\"which_character_shot_first?\"], \n",
    "               drop_first = True) # useful for onehotencoding and also turing yeses and nos into 0s and 1s. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5: The war with Star Wars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grand Question 1\n",
    "**Shorten the column names and clean them up for easier use with pandas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grand Question 2\n",
    "**Please validate that the data provided on GitHub lines up with the article by recreating 2 of their visuals and calculating 2 summaries that they report in the article.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grand Question 3\n",
    "**Clean and format the data so that it can be used in a machine learning model. As you format the data, you should complete each item listed below. In your final report provide example(s) of the reformatted data with a short description of the changes made.**\n",
    "\n",
    "a. Filter the dataset to respondents that have seen at least one film.\n",
    "\n",
    "b. Create a new column that converts the age ranges to a single number. Drop the age range categorical column.\n",
    "\n",
    "c. Create a new column that converts the school groupings to a single number. Drop the school categorical \n",
    "column.\n",
    "\n",
    "d. Create a new column that converts the income ranges to a single number. Drop the income range categorical \n",
    "column.\n",
    "\n",
    "e. Create your target (also known as \"y\" or \"label\") column based on the new income range column.\n",
    "\n",
    "f. One-hot encode all remaining categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grand Question 4\n",
    "**Build a machine learning model that predicts whether a person makes more than $50k.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3269ba1cb23deedadf404aebb4fbd50b01bdb34b2ceb15f81103dfd008217e9a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('sklearn-venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
